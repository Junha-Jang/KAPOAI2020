{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lunch_outside.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXGbSWGlkw8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivfGVf9Zk6sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOARD_ROWS = 7\n",
        "BOARD_COLS = 7"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cip6XuuTlAHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class State:\n",
        "  def __init__(self, p1, p2):\n",
        "    self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "    self.board[0, 0] = self.board[BOARD_ROWS-1, BOARD_COLS-1] = 1\n",
        "    self.board[BOARD_ROWS-1, 0] = self.board[0, BOARD_COLS-1] = -1\n",
        "    self.p1 = p1\n",
        "    self.p2 = p2\n",
        "    self.isEnd = False\n",
        "    self.boardHash = None\n",
        "    # init p1 plays first\n",
        "    self.playerSymbol = 1\n",
        "\n",
        "  def cantmove(self):\n",
        "    for i in range(BOARD_ROWS):\n",
        "      for j in range(BOARD_COLS):\n",
        "        if self.board[i, j] == 0:\n",
        "          self.board[i, j] = -self.playerSymbol\n",
        "    return None\n",
        "\n",
        "  def winner(self):\n",
        "    if sum(map(sum, map(abs, self.board))) == BOARD_ROWS*BOARD_COLS:\n",
        "      self.isEnd = True\n",
        "      return sum(map(sum, self.board))\n",
        "    self.isEnd = False\n",
        "    return None\n",
        "\n",
        "  def availableActions(self):\n",
        "    Actions = []\n",
        "    for i in range(BOARD_ROWS):\n",
        "        for j in range(BOARD_COLS):\n",
        "            if self.board[i, j] == self.playerSymbol:\n",
        "                for ii in range(-2,3):\n",
        "                    for jj in range(-2,3):\n",
        "                        if ii == 0 and jj == 0:\n",
        "                          continue\n",
        "                        if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
        "                          continue\n",
        "                        if self.board[i + ii, j + jj] == 0:\n",
        "                          act = i\n",
        "                          act = act*BOARD_COLS + j\n",
        "                          act = act*BOARD_COLS + i + ii\n",
        "                          act = act*BOARD_COLS + j + jj\n",
        "                          Actions.append(act)\n",
        "    return Actions\n",
        "\n",
        "    def updateState(self, Action):\n",
        "        position = []\n",
        "        for i in range(4):\n",
        "          position[3-i] = Action % BOARD_COLS\n",
        "          Action /= BOARD_COLS\n",
        "        ii = position[2] - position[0]\n",
        "        jj = position[3] - position[1]\n",
        "        if max(abs(ii), abs(jj)) == 2:\n",
        "            self.board[position[0:2]] = 0\n",
        "        \n",
        "        dx1 = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
        "        dy1 = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
        "        i, j = position[2:4]\n",
        "        self.board[i, j] = self.playerSymbol\n",
        "        for ii, jj in zip(dx1, dy1):\n",
        "            if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
        "                continue\n",
        "            if self.board[i + ii, j + jj] == -self.playerSymbol:\n",
        "                self.board[i + ii, j + jj] = self.playerSymbol\n",
        "            \n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        self.p1.feedReward(result)\n",
        "        self.p2.feedReward(-result)\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.board[0, 0] = self.board[BOARD_ROWS-1, BOARD_COLS-1] = 1\n",
        "        self.board[BOARD_ROWS-1, 0] = self.board[0, BOARD_COLS-1] = -1\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ksa-VSTmN-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Player:\n",
        "  def __init__(self, name, exp_rate=0.1):\n",
        "    self.name = name\n",
        "    self.lr = 0.2\n",
        "    self.exp_rate = exp_rate\n",
        "    self.decay_gamma = 0.95\n",
        "\n",
        "  def build_model(self):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(7, 7), activation='relu'))\n",
        "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(5, 5), activation='relu'))\n",
        "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(3, 3), activation='relu'))\n",
        "    model.add(Dense(64 * BOARD_COLS * BOARD_COLS, activation='relu'))\n",
        "    model.add(Dense(BOARD_COLS**4, activation='relu'))\n",
        "    print(model.summary())\n",
        "    model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "    return model\n",
        "\n",
        "  def getAction(self, state):\n",
        "    if np.random.rand() <= self.epsilon\n",
        "       # 무작위 행동 반환\n",
        "      return random.randrange(self.action_size)\n",
        "    else:\n",
        "       # 모델로부터 행동 산출\n",
        "      state = np.float32(state)\n",
        "      q_values = self.model.predict(state)\n",
        "      return np.argmax(q_values[0])\n",
        "\n",
        "  def train_model(self):\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HZbfESVy3rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ ==\" __main__\":\n",
        "  agent = Player()\n",
        "  agent.build_model()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsmQPdMNy522",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}